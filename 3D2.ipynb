{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9JU12/AnLxhVtYHLlCvIc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baroodb/code_base/blob/main/3D2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfhraYlYx7XA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58a755b-4aa0-4e81-fbd1-50155bafc449"
      },
      "source": [
        "!git clone https://github.com/vt-vl-lab/3d-photo-inpainting.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '3d-photo-inpainting'...\n",
            "remote: Enumerating objects: 372, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 372 (delta 9), reused 15 (delta 9), pack-reused 350\u001b[K\n",
            "Receiving objects: 100% (372/372), 130.14 MiB | 30.56 MiB/s, done.\n",
            "Resolving deltas: 100% (201/201), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPJtaq8fy882",
        "outputId": "d7673200-a9f8-4678-c094-5783c2e47ee1"
      },
      "source": [
        "%cd 3d-photo-inpainting/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3d-photo-inpainting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0SRNiP8zHIC",
        "outputId": "0a4b7c7f-7912-4383-93a9-1628613349f9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "argument.yml\t\t download.sh  mesh_tools.py   requirements.txt\n",
            "bilateral_filtering.py\t image\t      MiDaS\t      utils.py\n",
            "boostmonodepth_utils.py  LICENSE      networks.py     video\n",
            "depth\t\t\t main.py      pyproject.toml\n",
            "DOCUMENTATION.md\t mesh.py      README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIKZE7C5zL9Z",
        "outputId": "8ee08d58-1fe9-4115-e401-ff5f4463a13c"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python==4.2.0.32\n",
            "  Downloading opencv_python-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl (28.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2 MB 57 kB/s \n",
            "\u001b[?25hCollecting vispy==0.6.4\n",
            "  Downloading vispy-0.6.4-cp37-cp37m-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 29.5 MB/s \n",
            "\u001b[?25hCollecting moviepy==1.0.2\n",
            "  Downloading moviepy-1.0.2.tar.gz (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 17.8 MB/s \n",
            "\u001b[?25hCollecting transforms3d==0.3.1\n",
            "  Downloading transforms3d-0.3.1.tar.gz (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting networkx==2.3\n",
            "  Downloading networkx-2.3.zip (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 36.4 MB/s \n",
            "\u001b[?25hCollecting cynetworkx\n",
            "  Downloading cynetworkx-2.2rc1.dev20180527181709.tar.gz (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 120 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.2.0.32->-r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting freetype-py\n",
            "  Downloading freetype_py-2.2.0-py3-none-manylinux1_x86_64.whl (890 kB)\n",
            "\u001b[K     |████████████████████████████████| 890 kB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.2->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.2->-r requirements.txt (line 3)) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.2->-r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.9.tar.gz (10 kB)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 22.4 MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "  Downloading imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 99 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.2->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.2->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.2->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.2->-r requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.2->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 7)) (1.15.0)\n",
            "Building wheels for collected packages: moviepy, transforms3d, networkx, proglog, cynetworkx\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.2-py3-none-any.whl size=110746 sha256=05db02d8d0860ccba12019c4d7435fc7344fa33af22598a63c72c1b80ab8f923\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/36/f2/32c37d2b7a4f04622ccec875f71ebf5f33f892cea410f26454\n",
            "  Building wheel for transforms3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transforms3d: filename=transforms3d-0.3.1-py3-none-any.whl size=59373 sha256=528f52107dfb29e4d1d9299addd3e27247173d8361ab9bca549c06d16ea03f1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b7/93/8985551f83720ce37548a5b543c75380bb707955a9c2c5d28c\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556009 sha256=05355f55c432cd36694e8a22e53f0e0c228dcc8536e1592007210c1aa2fc03f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/e6/b8/4efaab31158e9e9ca9ed80b11f6b11130bac9a9672b3cbbeaf\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-py3-none-any.whl size=6157 sha256=ce2f00c422915069e6aa460fd7b20483864294e78235ca270e4ef8fc1ee7c77f\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/36/1f/dc61e6ac10781d63cf6fa045eb09fa613a667384e12cb6e6e0\n",
            "  Building wheel for cynetworkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cynetworkx: filename=cynetworkx-2.2rc1.dev20180527181709-cp37-cp37m-linux_x86_64.whl size=44363497 sha256=1110b670b9ec00a42347da503f3a156680ba05e41b0ade3f72705aeb0a28db81\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/12/03/144ca08a04b3fe366a6ee25cb9160bd586254f842f650163ca\n",
            "Successfully built moviepy transforms3d networkx proglog cynetworkx\n",
            "Installing collected packages: proglog, networkx, imageio-ffmpeg, imageio, freetype-py, vispy, transforms3d, opencv-python, moviepy, cynetworkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cynetworkx-2.2rc1.dev20180527181709 freetype-py-2.2.0 imageio-2.9.0 imageio-ffmpeg-0.4.5 moviepy-1.0.2 networkx-2.3 opencv-python-4.2.0.32 proglog-0.1.9 transforms3d-0.3.1 vispy-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6orPTSU3M2s"
      },
      "source": [
        "!pip3 install torch==1.4.0 torchvision==0.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkjiBKB9V8gu",
        "outputId": "3666a0ba-0d18-4798-c74a-3225be8df49e"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/one_shot_3d_photography.git one_shot"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'one_shot'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 250 (delta 4), reused 8 (delta 2), pack-reused 238\u001b[K\n",
            "Receiving objects: 100% (250/250), 51.06 MiB | 33.20 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gSTtuV5X7yR",
        "outputId": "f0218447-ac07-462a-8682-c080d0bb57eb"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUnr78eGohng"
      },
      "source": [
        "%%bash\n",
        "chmod +x download.sh\n",
        "./download.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFms9rO7fYfb"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/3d-photo-inpainting/one_shot')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpQ3wGcmYtcZ"
      },
      "source": [
        "from MiDaS import run"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPTYWanD5BzG",
        "outputId": "17252aa5-81aa-40db-9269-97b2b61d7c08"
      },
      "source": [
        "%cd ../"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3d-photo-inpainting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWq-5DyBfX5N",
        "outputId": "b0413c3a-e6f9-4dee-beb8-ba244db9f8ba"
      },
      "source": [
        "!python main.py --config argument.yml"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on device 0\n",
            "\r  0% 0/1 [00:00<?, ?it/s]Current Source ==>  obama\n",
            "Running depth extraction at 1632961554.3751843\n",
            "Creating Tiefenrausch model from files...\n",
            "  Init net: 'one_shot/model/tiefenrausch.pb'\n",
            "  Predict net: 'one_shot/model/tiefenrausch.pb'\n",
            "image/obama.jpg\n",
            "depth/obama.npy\n",
            "depth/obama.png\n",
            "Reading image file 'image/obama.jpg'...\n",
            "Original python traceback for operator `2` in network `torch-jit-export_predict_int8_1` in exception above (most recent call last):\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 67, in <module>\n",
            "    sample['ref_img_fi'], os.path.join(config['depth_folder'], sample['src_pair_name']+'.npy'), os.path.join(config['depth_folder'], sample['src_pair_name']+'.png'))\n",
            "  File \"/content/3d-photo-inpainting/one_shot/cli.py\", line 57, in estimate_depth\n",
            "    ws.CreateNet(self.init_net)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caffe2/python/workspace.py\", line 182, in CreateNet\n",
            "    StringifyProto(net), overwrite,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caffe2/python/workspace.py\", line 216, in CallWithExceptionIntercept\n",
            "    return func(*args, **kwargs)\n",
            "RuntimeError: [enforce fail at operator.cc:75] blob != nullptr. op Int8Conv: Encountered a non-existing input blob: 1.first.conv.weight_int8\n",
            "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f6cfb637d37 in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: caffe2::OperatorBase::OperatorBase(caffe2::OperatorDef const&, caffe2::Workspace*) + 0x6a5 (0x7f6cfe76a205 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #2: <unknown function> + 0x3072a75 (0x7f6cfeafca75 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #3: <unknown function> + 0x310d171 (0x7f6cfeb97171 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #4: <unknown function> + 0x374ca5e (0x7f6cff1d6a5e in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #5: std::_Function_handler<std::unique_ptr<caffe2::OperatorBase, std::default_delete<caffe2::OperatorBase> > (caffe2::OperatorDef const&, caffe2::Workspace*), std::unique_ptr<caffe2::OperatorBase, std::default_delete<caffe2::OperatorBase> > (*)(caffe2::OperatorDef const&, caffe2::Workspace*)>::_M_invoke(std::_Any_data const&, caffe2::OperatorDef const&, caffe2::Workspace*&&) + 0xf (0x7f6cfe8765af in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #6: <unknown function> + 0x2cdd91c (0x7f6cfe76791c in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #7: caffe2::CreateOperator(caffe2::OperatorDef const&, caffe2::Workspace*, int) + 0x38c (0x7f6cfe768a2c in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #8: caffe2::SimpleNet::SimpleNet(std::shared_ptr<caffe2::NetDef const> const&, caffe2::Workspace*) + 0x187 (0x7f6cfe761117 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #9: <unknown function> + 0x2cd95be (0x7f6cfe7635be in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #10: std::_Function_handler<std::unique_ptr<caffe2::NetBase, std::default_delete<caffe2::NetBase> > (std::shared_ptr<caffe2::NetDef const> const&, caffe2::Workspace*), std::unique_ptr<caffe2::NetBase, std::default_delete<caffe2::NetBase> > (*)(std::shared_ptr<caffe2::NetDef const> const&, caffe2::Workspace*)>::_M_invoke(std::_Any_data const&, std::shared_ptr<caffe2::NetDef const> const&, caffe2::Workspace*&&) + 0xf (0x7f6cfe73823f in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #11: caffe2::CreateNet(std::shared_ptr<caffe2::NetDef const> const&, caffe2::Workspace*) + 0x464 (0x7f6cfe72a3e4 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #12: caffe2::Workspace::CreateNet(std::shared_ptr<caffe2::NetDef const> const&, bool) + 0xfe (0x7f6cfe7a5d0e in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #13: caffe2::Workspace::CreateNet(caffe2::NetDef const&, bool) + 0x90 (0x7f6cfe7abad0 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so)\n",
            "frame #14: <unknown function> + 0x5909c (0x7f6cf34bf09c in /usr/local/lib/python3.7/dist-packages/caffe2/python/caffe2_pybind11_state_gpu.cpython-37m-x86_64-linux-gnu.so)\n",
            "frame #15: <unknown function> + 0x59449 (0x7f6cf34bf449 in /usr/local/lib/python3.7/dist-packages/caffe2/python/caffe2_pybind11_state_gpu.cpython-37m-x86_64-linux-gnu.so)\n",
            "frame #16: <unknown function> + 0x946e1 (0x7f6cf34fa6e1 in /usr/local/lib/python3.7/dist-packages/caffe2/python/caffe2_pybind11_state_gpu.cpython-37m-x86_64-linux-gnu.so)\n",
            "<omitting python frames>\n",
            "frame #35: __libc_start_main + 0xe7 (0x7f6d961eebf7 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0J1ukTlbSYj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxDJ70-ttuE",
        "outputId": "5b76a0e5-3374-49d3-b3eb-3ff27ff964e1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('/content/3d-photo-inpainting/depth/obama.npy')\n",
        "data.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640, 640)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlbTFRH2uex7",
        "outputId": "b0726b2a-cac8-4618-9fd2-33ae10c49a79"
      },
      "source": [
        "!which python"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kml1NfWKuHff",
        "outputId": "13923061-82d7-46e8-8d88-2a78c517a6bc"
      },
      "source": [
        "!ls /usr/local/bin/python"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKscDmXOu9Zk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrCqBKhu9WY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTga6Mgcu9J-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKmbiy6uu7Gi"
      },
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "from functools import partial\n",
        "import vispy\n",
        "import scipy.misc as misc\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import time\n",
        "import sys\n",
        "from mesh import write_ply, read_ply, output_3d_photo\n",
        "from utils import get_MiDaS_samples, read_MiDaS_depth\n",
        "import torch\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "import imageio\n",
        "import copy\n",
        "from networks import Inpaint_Color_Net, Inpaint_Depth_Net, Inpaint_Edge_Net\n",
        "from MiDaS.run import run_depth\n",
        "from boostmonodepth_utils import run_boostmonodepth\n",
        "from MiDaS.monodepth_net import MonoDepthNet\n",
        "import MiDaS.MiDaS_utils as MiDaS_utils\n",
        "from bilateral_filtering import sparse_bilateral_filtering\n",
        "\n",
        "from one_shot.cli import DepthEstimatorCaffe2\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default='argument.yml',help='Configure of post processing')\n",
        "args = parser.parse_args()\n",
        "config = yaml.load(open(args.config, 'r'))\n",
        "if config['offscreen_rendering'] is True:\n",
        "    vispy.use(app='egl')\n",
        "os.makedirs(config['mesh_folder'], exist_ok=True)\n",
        "os.makedirs(config['video_folder'], exist_ok=True)\n",
        "os.makedirs(config['depth_folder'], exist_ok=True)\n",
        "\n",
        "sample_list = get_MiDaS_samples(config['src_folder'], config['depth_folder'], config, config['specific'])\n",
        "\n",
        "normal_canvas, all_canvas = None, None\n",
        "\n",
        "if isinstance(config[\"gpu_ids\"], int) and (config[\"gpu_ids\"] >= 0):\n",
        "    device = config[\"gpu_ids\"]\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"running on device {device}\")\n",
        "\n",
        "for idx in tqdm(range(len(sample_list))):\n",
        "    depth = None\n",
        "    sample = sample_list[idx]\n",
        "    print(\"Current Source ==> \", sample['src_pair_name'])\n",
        "    mesh_fi = os.path.join(config['mesh_folder'], sample['src_pair_name'] +'.ply')\n",
        "    image = imageio.imread(sample['ref_img_fi'])\n",
        "\n",
        "    print(f\"Running depth extraction at {time.time()}\")\n",
        "    if config['use_boostmonodepth'] is True:\n",
        "        run_boostmonodepth(sample['ref_img_fi'], config['src_folder'], config['depth_folder'])\n",
        "    elif config['require_midas'] is True:\n",
        "        run_depth([sample['ref_img_fi']], config['src_folder'], config['depth_folder'],\n",
        "                  config['MiDaS_model_ckpt'], MonoDepthNet, MiDaS_utils, target_w=640)\n",
        "\n",
        "    if 'npy' in config['depth_format']:\n",
        "        config['output_h'], config['output_w'] = np.load(sample['depth_fi']).shape[:2]\n",
        "    else:\n",
        "        config['output_h'], config['output_w'] = imageio.imread(sample['depth_fi']).shape[:2]\n",
        "    frac = config['longer_side_len'] / max(config['output_h'], config['output_w'])\n",
        "    config['output_h'], config['output_w'] = int(config['output_h'] * frac), int(config['output_w'] * frac)\n",
        "    config['original_h'], config['original_w'] = config['output_h'], config['output_w']\n",
        "    if image.ndim == 2:\n",
        "        image = image[..., None].repeat(3, -1)\n",
        "    if np.sum(np.abs(image[..., 0] - image[..., 1])) == 0 and np.sum(np.abs(image[..., 1] - image[..., 2])) == 0:\n",
        "        config['gray_image'] = True\n",
        "    else:\n",
        "        config['gray_image'] = False\n",
        "    image = cv2.resize(image, (config['output_w'], config['output_h']), interpolation=cv2.INTER_AREA)\n",
        "    depth = read_MiDaS_depth(sample['depth_fi'], 3.0, config['output_h'], config['output_w'])\n",
        "    mean_loc_depth = depth[depth.shape[0]//2, depth.shape[1]//2]\n",
        "    if not(config['load_ply'] is True and os.path.exists(mesh_fi)):\n",
        "        vis_photos, vis_depths = sparse_bilateral_filtering(depth.copy(), image.copy(), config, num_iter=config['sparse_iter'], spdb=False)\n",
        "        depth = vis_depths[-1]\n",
        "        model = None\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"Start Running 3D_Photo ...\")\n",
        "        print(f\"Loading edge model at {time.time()}\")\n",
        "        depth_edge_model = Inpaint_Edge_Net(init_weights=True)\n",
        "        depth_edge_weight = torch.load(config['depth_edge_model_ckpt'],\n",
        "                                       map_location=torch.device(device))\n",
        "        depth_edge_model.load_state_dict(depth_edge_weight)\n",
        "        depth_edge_model = depth_edge_model.to(device)\n",
        "        depth_edge_model.eval()\n",
        "\n",
        "        print(f\"Loading depth model at {time.time()}\")\n",
        "        depth_feat_model = Inpaint_Depth_Net()\n",
        "        depth_feat_weight = torch.load(config['depth_feat_model_ckpt'],\n",
        "                                       map_location=torch.device(device))\n",
        "        depth_feat_model.load_state_dict(depth_feat_weight, strict=True)\n",
        "        depth_feat_model = depth_feat_model.to(device)\n",
        "        depth_feat_model.eval()\n",
        "        depth_feat_model = depth_feat_model.to(device)\n",
        "        print(f\"Loading rgb model at {time.time()}\")\n",
        "        rgb_model = Inpaint_Color_Net()\n",
        "        rgb_feat_weight = torch.load(config['rgb_feat_model_ckpt'],\n",
        "                                     map_location=torch.device(device))\n",
        "        rgb_model.load_state_dict(rgb_feat_weight)\n",
        "        rgb_model.eval()\n",
        "        rgb_model = rgb_model.to(device)\n",
        "        graph = None\n",
        "\n",
        "\n",
        "        print(f\"Writing depth ply (and basically doing everything) at {time.time()}\")\n",
        "        rt_info = write_ply(image,\n",
        "                              depth,\n",
        "                              sample['int_mtx'],\n",
        "                              mesh_fi,\n",
        "                              config,\n",
        "                              rgb_model,\n",
        "                              depth_edge_model,\n",
        "                              depth_edge_model,\n",
        "                              depth_feat_model)\n",
        "\n",
        "        if rt_info is False:\n",
        "            continue\n",
        "        rgb_model = None\n",
        "        color_feat_model = None\n",
        "        depth_edge_model = None\n",
        "        depth_feat_model = None\n",
        "        torch.cuda.empty_cache()\n",
        "    if config['save_ply'] is True or config['load_ply'] is True:\n",
        "        verts, colors, faces, Height, Width, hFov, vFov = read_ply(mesh_fi)\n",
        "    else:\n",
        "        verts, colors, faces, Height, Width, hFov, vFov = rt_info\n",
        "\n",
        "\n",
        "    print(f\"Making video at {time.time()}\")\n",
        "    videos_poses, video_basename = copy.deepcopy(sample['tgts_poses']), sample['tgt_name']\n",
        "    top = (config.get('original_h') // 2 - sample['int_mtx'][1, 2] * config['output_h'])\n",
        "    left = (config.get('original_w') // 2 - sample['int_mtx'][0, 2] * config['output_w'])\n",
        "    down, right = top + config['output_h'], left + config['output_w']\n",
        "    border = [int(xx) for xx in [top, down, left, right]]\n",
        "    normal_canvas, all_canvas = output_3d_photo(verts.copy(), colors.copy(), faces.copy(), copy.deepcopy(Height), copy.deepcopy(Width), copy.deepcopy(hFov), copy.deepcopy(vFov),\n",
        "                        copy.deepcopy(sample['tgt_pose']), sample['video_postfix'], copy.deepcopy(sample['ref_pose']), copy.deepcopy(config['video_folder']),\n",
        "                        image.copy(), copy.deepcopy(sample['int_mtx']), config, image,\n",
        "                        videos_poses, video_basename, config.get('original_h'), config.get('original_w'), border=border, depth=depth, normal_canvas=normal_canvas, all_canvas=all_canvas,\n",
        "                        mean_loc_depth=mean_loc_depth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OU4PwX64bsT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-DFy8Mi4bQL"
      },
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "from functools import partial\n",
        "import vispy\n",
        "import scipy.misc as misc\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import time\n",
        "import sys\n",
        "from mesh import write_ply, read_ply, output_3d_photo\n",
        "from utils import get_MiDaS_samples, read_MiDaS_depth\n",
        "import torch\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "import imageio\n",
        "import copy\n",
        "from networks import Inpaint_Color_Net, Inpaint_Depth_Net, Inpaint_Edge_Net\n",
        "from MiDaS.run import run_depth\n",
        "from boostmonodepth_utils import run_boostmonodepth\n",
        "from MiDaS.monodepth_net import MonoDepthNet\n",
        "import MiDaS.MiDaS_utils as MiDaS_utils\n",
        "from bilateral_filtering import sparse_bilateral_filtering\n",
        "\n",
        "from one_shot.cli import DepthEstimatorCaffe2\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--config', type=str, default='argument.yml',help='Configure of post processing')\n",
        "args = parser.parse_args()\n",
        "config = yaml.load(open(args.config, 'r'))\n",
        "if config['offscreen_rendering'] is True:\n",
        "    vispy.use(app='egl')\n",
        "os.makedirs(config['mesh_folder'], exist_ok=True)\n",
        "os.makedirs(config['video_folder'], exist_ok=True)\n",
        "os.makedirs(config['depth_folder'], exist_ok=True)\n",
        "\n",
        "sample_list = get_MiDaS_samples(config['src_folder'], config['depth_folder'], config, config['specific'])\n",
        "\n",
        "normal_canvas, all_canvas = None, None\n",
        "\n",
        "if isinstance(config[\"gpu_ids\"], int) and (config[\"gpu_ids\"] >= 0):\n",
        "    device = config[\"gpu_ids\"]\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"running on device {device}\")\n",
        "\n",
        "for idx in tqdm(range(len(sample_list))):\n",
        "    depth = None\n",
        "    sample = sample_list[idx]\n",
        "    print(\"Current Source ==> \", sample['src_pair_name'])\n",
        "    mesh_fi = os.path.join(config['mesh_folder'], sample['src_pair_name'] +'.ply')\n",
        "    image = imageio.imread(sample['ref_img_fi'])\n",
        "\n",
        "    print(f\"Running depth extraction at {time.time()}\")\n",
        "\n",
        "    if config['use_boostmonodepth'] is True:\n",
        "        run_boostmonodepth(sample['ref_img_fi'], config['src_folder'], config['depth_folder'])\n",
        "    elif config['require_midas'] is True:\n",
        "        run_depth([sample['ref_img_fi']], config['src_folder'], config['depth_folder'],\n",
        "                  config['MiDaS_model_ckpt'], MonoDepthNet, MiDaS_utils, target_w=640)\n",
        "\n",
        "\n",
        "\n",
        "    if 'npy' in config['depth_format']:\n",
        "        config['output_h'], config['output_w'] = np.load(sample['depth_fi']).shape[:2]\n",
        "    else:\n",
        "        config['output_h'], config['output_w'] = imageio.imread(sample['depth_fi']).shape[:2]\n",
        "\n",
        "    print(config['output_h'], config['output_w'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iAl5NhwCbFa"
      },
      "source": [
        " if 'npy' in config['depth_format']:\n",
        "        config['output_h'], config['output_w'] = np.load(sample['depth_fi']).shape[:2]\n",
        "    else:\n",
        "        config['output_h'], config['output_w'] = imageio.imread(sample['depth_fi']).shape[:2]\n",
        "    frac = config['longer_side_len'] / max(config['output_h'], config['output_w'])\n",
        "    config['output_h'], config['output_w'] = int(config['output_h'] * frac), int(config['output_w'] * frac)\n",
        "    config['original_h'], config['original_w'] = config['output_h'], config['output_w']\n",
        "    if image.ndim == 2:\n",
        "        image = image[..., None].repeat(3, -1)\n",
        "    if np.sum(np.abs(image[..., 0] - image[..., 1])) == 0 and np.sum(np.abs(image[..., 1] - image[..., 2])) == 0:\n",
        "        config['gray_image'] = True\n",
        "    else:\n",
        "        config['gray_image'] = False\n",
        "    image = cv2.resize(image, (config['output_w'], config['output_h']), interpolation=cv2.INTER_AREA)\n",
        "    depth = read_MiDaS_depth(sample['depth_fi'], 3.0, config['output_h'], config['output_w'])\n",
        "    mean_loc_depth = depth[depth.shape[0]//2, depth.shape[1]//2]\n",
        "    if not(config['load_ply'] is True and os.path.exists(mesh_fi)):\n",
        "        vis_photos, vis_depths = sparse_bilateral_filtering(depth.copy(), image.copy(), config, num_iter=config['sparse_iter'], spdb=False)\n",
        "        depth = vis_depths[-1]\n",
        "        model = None\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"Start Running 3D_Photo ...\")\n",
        "        print(f\"Loading edge model at {time.time()}\")\n",
        "        depth_edge_model = Inpaint_Edge_Net(init_weights=True)\n",
        "        depth_edge_weight = torch.load(config['depth_edge_model_ckpt'],\n",
        "                                       map_location=torch.device(device))\n",
        "        depth_edge_model.load_state_dict(depth_edge_weight)\n",
        "        depth_edge_model = depth_edge_model.to(device)\n",
        "        depth_edge_model.eval()\n",
        "\n",
        "        print(f\"Loading depth model at {time.time()}\")\n",
        "        depth_feat_model = Inpaint_Depth_Net()\n",
        "        depth_feat_weight = torch.load(config['depth_feat_model_ckpt'],\n",
        "                                       map_location=torch.device(device))\n",
        "        depth_feat_model.load_state_dict(depth_feat_weight, strict=True)\n",
        "        depth_feat_model = depth_feat_model.to(device)\n",
        "        depth_feat_model.eval()\n",
        "        depth_feat_model = depth_feat_model.to(device)\n",
        "        print(f\"Loading rgb model at {time.time()}\")\n",
        "        rgb_model = Inpaint_Color_Net()\n",
        "        rgb_feat_weight = torch.load(config['rgb_feat_model_ckpt'],\n",
        "                                     map_location=torch.device(device))\n",
        "        rgb_model.load_state_dict(rgb_feat_weight)\n",
        "        rgb_model.eval()\n",
        "        rgb_model = rgb_model.to(device)\n",
        "        graph = None\n",
        "\n",
        "\n",
        "        print(f\"Writing depth ply (and basically doing everything) at {time.time()}\")\n",
        "        rt_info = write_ply(image,\n",
        "                              depth,\n",
        "                              sample['int_mtx'],\n",
        "                              mesh_fi,\n",
        "                              config,\n",
        "                              rgb_model,\n",
        "                              depth_edge_model,\n",
        "                              depth_edge_model,\n",
        "                              depth_feat_model)\n",
        "\n",
        "        if rt_info is False:\n",
        "            continue\n",
        "        rgb_model = None\n",
        "        color_feat_model = None\n",
        "        depth_edge_model = None\n",
        "        depth_feat_model = None\n",
        "        torch.cuda.empty_cache()\n",
        "    if config['save_ply'] is True or config['load_ply'] is True:\n",
        "        verts, colors, faces, Height, Width, hFov, vFov = read_ply(mesh_fi)\n",
        "    else:\n",
        "        verts, colors, faces, Height, Width, hFov, vFov = rt_info\n",
        "\n",
        "\n",
        "    print(f\"Making video at {time.time()}\")\n",
        "    videos_poses, video_basename = copy.deepcopy(sample['tgts_poses']), sample['tgt_name']\n",
        "    top = (config.get('original_h') // 2 - sample['int_mtx'][1, 2] * config['output_h'])\n",
        "    left = (config.get('original_w') // 2 - sample['int_mtx'][0, 2] * config['output_w'])\n",
        "    down, right = top + config['output_h'], left + config['output_w']\n",
        "    border = [int(xx) for xx in [top, down, left, right]]\n",
        "    normal_canvas, all_canvas = output_3d_photo(verts.copy(), colors.copy(), faces.copy(), copy.deepcopy(Height), copy.deepcopy(Width), copy.deepcopy(hFov), copy.deepcopy(vFov),\n",
        "                        copy.deepcopy(sample['tgt_pose']), sample['video_postfix'], copy.deepcopy(sample['ref_pose']), copy.deepcopy(config['video_folder']),\n",
        "                        image.copy(), copy.deepcopy(sample['int_mtx']), config, image,\n",
        "                        videos_poses, video_basename, config.get('original_h'), config.get('original_w'), border=border, depth=depth, normal_canvas=normal_canvas, all_canvas=all_canvas,\n",
        "                        mean_loc_depth=mean_loc_depth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVEylT7MzFI6",
        "outputId": "676cba3d-e117-4c38-acc8-97c1092c821f"
      },
      "source": [
        "%cd one_shot/"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3d-photo-inpainting/one_shot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXqIVTpSzK0s",
        "outputId": "e56fe7fe-fd94-42a7-fecf-bc4b940350ff"
      },
      "source": [
        "!python cli.py --src_dir /content/3d-photo-inpainting/image --out_dir /content/3d-photo-inpainting/depth --vis_dir /content/3d-photo-inpainting/depth\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings:\n",
            "  init_net: model/tiefenrausch_init.pb\n",
            "  predict_net: model/tiefenrausch.pb\n",
            "  src_file: None\n",
            "  out_file: None\n",
            "  vis_file: None\n",
            "  src_dir: /content/3d-photo-inpainting/image\n",
            "  out_dir: /content/3d-photo-inpainting/depth\n",
            "  vis_dir: /content/3d-photo-inpainting/depth\n",
            "Creating Tiefenrausch model from files...\n",
            "  Init net: 'model/tiefenrausch_init.pb'\n",
            "  Predict net: 'model/tiefenrausch.pb'\n",
            "Reading image file '/content/3d-photo-inpainting/image/obama.jpg'...\n",
            "Writing depth file '/content/3d-photo-inpainting/depth/obama.npy'...\n",
            "Writing visualization file '/content/3d-photo-inpainting/depth/obama.png'...\n",
            "Finished.\n"
          ]
        }
      ]
    }
  ]
}